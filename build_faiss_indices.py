"""
Script para construir m√∫ltiples √≠ndices FAISS con diferentes m√©todos de indexaci√≥n.
Crea √≠ndices Flat, IVF, IVFPQ y HNSW para cada extractor de caracter√≠sticas.
"""

import os
import sys
import json
import numpy as np
import faiss
from pathlib import Path
from typing import Tuple
import time


class FAISSIndexBuilder:
    """
    Constructor de √≠ndices FAISS con diferentes m√©todos de indexaci√≥n.
    """
    
    def __init__(self, features: np.ndarray, dimension: int):
        """
        Inicializa el constructor.
        
        Args:
            features: Matriz de caracter√≠sticas (N x D)
            dimension: Dimensi√≥n de los vectores
        """
        self.features = features.astype(np.float32)
        self.dimension = dimension
        self.num_vectors = features.shape[0]
        
        print(f"  Dataset: {self.num_vectors} vectores de dimensi√≥n {self.dimension}")
    
    def build_flat_index(self) -> Tuple[faiss.Index, dict]:
        """
        Construye un √≠ndice Flat (b√∫squeda exacta con L2).
        
        Returns:
            tuple: (√≠ndice, metadata)
        """
        print("\n  [1/4] Construyendo IndexFlatL2 (b√∫squeda exacta)...")
        start_time = time.time()
        
        # Crear √≠ndice
        index = faiss.IndexFlatL2(self.dimension)
        
        # Agregar vectores
        index.add(self.features)
        
        build_time = time.time() - start_time
        
        metadata = {
            'type': 'IndexFlatL2',
            'description': 'B√∫squeda exacta con distancia L2',
            'dimension': self.dimension,
            'num_vectors': index.ntotal,
            'build_time': build_time,
            'uses': 'Datasets peque√±os, b√∫squeda exacta garantizada'
        }
        
        print(f"    ‚úì Completado en {build_time:.2f}s")
        print(f"    ‚úì Vectores indexados: {index.ntotal}")
        
        return index, metadata
    
    def build_ivf_index(self, nlist: int = None) -> Tuple[faiss.Index, dict]:
        """
        Construye un √≠ndice IVF (Inverted File).
        
        Args:
            nlist: N√∫mero de clusters (por defecto: sqrt(N))
            
        Returns:
            tuple: (√≠ndice, metadata)
        """
        if nlist is None:
            nlist = min(int(np.sqrt(self.num_vectors)), 100)
        
        print(f"\n  [2/4] Construyendo IndexIVFFlat (nlist={nlist})...")
        start_time = time.time()
        
        # Crear √≠ndice base (quantizer)
        quantizer = faiss.IndexFlatL2(self.dimension)
        
        # Crear √≠ndice IVF
        index = faiss.IndexIVFFlat(quantizer, self.dimension, nlist)
        
        # Entrenar el √≠ndice
        print(f"    - Entrenando con {self.num_vectors} vectores...")
        index.train(self.features)
        
        # Agregar vectores
        print(f"    - Agregando vectores al √≠ndice...")
        index.add(self.features)
        
        # Configurar nprobe (n√∫mero de clusters a buscar)
        index.nprobe = min(10, nlist)
        
        build_time = time.time() - start_time
        
        metadata = {
            'type': 'IndexIVFFlat',
            'description': 'B√∫squeda aproximada con clustering',
            'dimension': self.dimension,
            'num_vectors': index.ntotal,
            'nlist': nlist,
            'nprobe': index.nprobe,
            'build_time': build_time,
            'uses': 'Datasets medianos/grandes, b√∫squeda r√°pida'
        }
        
        print(f"    ‚úì Completado en {build_time:.2f}s")
        print(f"    ‚úì Vectores indexados: {index.ntotal}")
        print(f"    ‚úì Clusters: {nlist}, nprobe: {index.nprobe}")
        
        return index, metadata
    
    def build_ivfpq_index(self, nlist: int = None, m: int = 8, 
                          nbits: int = 8) -> Tuple[faiss.Index, dict]:
        """
        Construye un √≠ndice IVFPQ (IVF + Product Quantization).
        
        Args:
            nlist: N√∫mero de clusters
            m: N√∫mero de sub-vectores para PQ
            nbits: Bits por sub-vector
            
        Returns:
            tuple: (√≠ndice, metadata)
        """
        if nlist is None:
            nlist = min(int(np.sqrt(self.num_vectors)), 100)
        
        # Ajustar m para que divida la dimensi√≥n
        if self.dimension % m != 0:
            m = 8 if self.dimension >= 64 else 4
            while self.dimension % m != 0 and m > 1:
                m -= 1
        
        print(f"\n  [3/4] Construyendo IndexIVFPQ (nlist={nlist}, m={m}, nbits={nbits})...")
        start_time = time.time()
        
        # Crear √≠ndice base
        quantizer = faiss.IndexFlatL2(self.dimension)
        
        # Crear √≠ndice IVFPQ
        index = faiss.IndexIVFPQ(quantizer, self.dimension, nlist, m, nbits)
        
        # Entrenar
        print(f"    - Entrenando con {self.num_vectors} vectores...")
        index.train(self.features)
        
        # Agregar vectores
        print(f"    - Agregando vectores al √≠ndice...")
        index.add(self.features)
        
        # Configurar nprobe
        index.nprobe = min(10, nlist)
        
        build_time = time.time() - start_time
        
        # Calcular compresi√≥n
        original_size = self.num_vectors * self.dimension * 4  # float32
        compressed_size = index.ntotal * m * nbits / 8
        compression_ratio = original_size / compressed_size
        
        metadata = {
            'type': 'IndexIVFPQ',
            'description': 'B√∫squeda aproximada con compresi√≥n',
            'dimension': self.dimension,
            'num_vectors': index.ntotal,
            'nlist': nlist,
            'nprobe': index.nprobe,
            'm': m,
            'nbits': nbits,
            'build_time': build_time,
            'compression_ratio': compression_ratio,
            'uses': 'Datasets grandes, memoria limitada'
        }
        
        print(f"    ‚úì Completado en {build_time:.2f}s")
        print(f"    ‚úì Vectores indexados: {index.ntotal}")
        print(f"    ‚úì Compresi√≥n: {compression_ratio:.1f}x")
        
        return index, metadata
    
    def build_hnsw_index(self, M: int = 32) -> Tuple[faiss.Index, dict]:
        """
        Construye un √≠ndice HNSW (Hierarchical Navigable Small World).
        
        Args:
            M: N√∫mero de conexiones por nodo
            
        Returns:
            tuple: (√≠ndice, metadata)
        """
        print(f"\n  [4/4] Construyendo IndexHNSWFlat (M={M})...")
        start_time = time.time()
        
        # Crear √≠ndice HNSW
        index = faiss.IndexHNSWFlat(self.dimension, M)
        
        # Agregar vectores (HNSW no requiere entrenamiento)
        print(f"    - Agregando vectores al √≠ndice...")
        index.add(self.features)
        
        build_time = time.time() - start_time
        
        metadata = {
            'type': 'IndexHNSWFlat',
            'description': 'B√∫squeda aproximada con grafos',
            'dimension': self.dimension,
            'num_vectors': index.ntotal,
            'M': M,
            'build_time': build_time,
            'uses': 'Alta precisi√≥n, b√∫squeda muy r√°pida'
        }
        
        print(f"    ‚úì Completado en {build_time:.2f}s")
        print(f"    ‚úì Vectores indexados: {index.ntotal}")
        
        return index, metadata


def build_all_indices_for_extractor(extractor_name: str, 
                                    features_dir: str = "features",
                                    output_dir: str = "faiss_indices"):
    """
    Construye todos los tipos de √≠ndices para un extractor.
    
    Args:
        extractor_name: Nombre del extractor
        features_dir: Directorio de caracter√≠sticas
        output_dir: Directorio de salida
    """
    print(f"\n{'='*60}")
    print(f"PROCESANDO: {extractor_name}")
    print(f"{'='*60}")
    
    # Cargar caracter√≠sticas
    features_file = Path(features_dir) / f"{extractor_name}_features.npy"
    
    if not features_file.exists():
        print(f"‚úó Error: No se encontr√≥ {features_file}")
        return
    
    print(f"\nCargando caracter√≠sticas desde {features_file}...")
    features = np.load(features_file)
    
    print(f"  ‚úì Cargadas {features.shape[0]} caracter√≠sticas")
    print(f"  ‚úì Dimensi√≥n: {features.shape[1]}")
    
    # Crear constructor
    builder = FAISSIndexBuilder(features, features.shape[1])
    
    # Crear directorio de salida
    output_path = Path(output_dir) / extractor_name
    output_path.mkdir(parents=True, exist_ok=True)
    
    # Construir todos los √≠ndices
    indices_info = {}
    
    # 1. Flat Index
    index, metadata = builder.build_flat_index()
    index_file = output_path / "index_flat.index"
    faiss.write_index(index, str(index_file))
    indices_info['flat'] = metadata
    print(f"    üíæ Guardado: {index_file}")
    
    # 2. IVF Index
    index, metadata = builder.build_ivf_index()
    index_file = output_path / "index_ivf.index"
    faiss.write_index(index, str(index_file))
    indices_info['ivf'] = metadata
    print(f"    üíæ Guardado: {index_file}")
    
    # 3. IVFPQ Index
    index, metadata = builder.build_ivfpq_index()
    index_file = output_path / "index_ivfpq.index"
    faiss.write_index(index, str(index_file))
    indices_info['ivfpq'] = metadata
    print(f"    üíæ Guardado: {index_file}")
    
    # 4. HNSW Index
    index, metadata = builder.build_hnsw_index()
    index_file = output_path / "index_hnsw.index"
    faiss.write_index(index, str(index_file))
    indices_info['hnsw'] = metadata
    print(f"    üíæ Guardado: {index_file}")
    
    # Guardar metadata de todos los √≠ndices
    metadata_file = output_path / "indices_info.json"
    with open(metadata_file, 'w') as f:
        json.dump(indices_info, f, indent=2)
    
    print(f"\n  ‚úì Todos los √≠ndices creados para {extractor_name}")
    print(f"  ‚úì Metadata guardada en {metadata_file}")


def main():
    """
    Funci√≥n principal.
    """
    print("="*60)
    print("CONSTRUCCI√ìN DE √çNDICES FAISS")
    print("="*60)
    print("\nTipos de √≠ndices a construir:")
    print("  1. IndexFlatL2    - B√∫squeda exacta")
    print("  2. IndexIVFFlat   - B√∫squeda aproximada r√°pida")
    print("  3. IndexIVFPQ     - B√∫squeda aproximada con compresi√≥n")
    print("  4. IndexHNSWFlat  - B√∫squeda aproximada con grafos")
    
    # Verificar directorio de caracter√≠sticas
    features_dir = Path("features")
    if not features_dir.exists():
        print("\n‚úó Error: Directorio 'features/' no encontrado")
        print("  Ejecuta extract_all_features.py primero")
        return
    
    # Buscar archivos de caracter√≠sticas
    feature_files = list(features_dir.glob("*_features.npy"))
    
    if not feature_files:
        print("\n‚úó Error: No se encontraron archivos de caracter√≠sticas")
        print("  Ejecuta extract_all_features.py primero")
        return
    
    # Extraer nombres de extractores
    extractors = [f.stem.replace('_features', '') for f in feature_files]
    
    print(f"\n‚úì Encontrados {len(extractors)} extractores:")
    for ext in extractors:
        print(f"  - {ext}")
    
    # Construir √≠ndices para cada extractor
    for extractor_name in extractors:
        build_all_indices_for_extractor(extractor_name)
    
    print(f"\n{'='*60}")
    print("‚úì CONSTRUCCI√ìN DE √çNDICES COMPLETADA")
    print(f"{'='*60}")
    print("\nResumen:")
    print(f"  - Extractores procesados: {len(extractors)}")
    print(f"  - √çndices por extractor: 4")
    print(f"  - Total de √≠ndices: {len(extractors) * 4}")
    print("\nArchivos generados en el directorio 'faiss_indices/'")
    print("  Estructura: faiss_indices/<extractor>/index_<tipo>.index")


if __name__ == "__main__":
    main()
